{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7883532f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\kk\\anaconda3\\lib\\site-packages (from kaggle) (1.15.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\kk\\anaconda3\\lib\\site-packages (from kaggle) (2020.12.5)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\kk\\anaconda3\\lib\\site-packages (from kaggle) (2.8.1)\n",
      "Requirement already satisfied: requests in c:\\users\\kk\\anaconda3\\lib\\site-packages (from kaggle) (2.25.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kk\\anaconda3\\lib\\site-packages (from kaggle) (4.64.0)\n",
      "Collecting python-slugify\n",
      "  Downloading python_slugify-6.1.2-py2.py3-none-any.whl (9.4 kB)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\kk\\anaconda3\\lib\\site-packages (from kaggle) (1.26.4)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\kk\\anaconda3\\lib\\site-packages (from requests->kaggle) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\kk\\anaconda3\\lib\\site-packages (from requests->kaggle) (4.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kk\\anaconda3\\lib\\site-packages (from tqdm->kaggle) (0.4.4)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py): started\n",
      "  Building wheel for kaggle (setup.py): finished with status 'done'\n",
      "  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73053 sha256=8111932931c6aacb903e16e6a99f1beaf5dfccbc2d66c2684f5e21f97563cf8a\n",
      "  Stored in directory: c:\\users\\kk\\appdata\\local\\pip\\cache\\wheels\\29\\da\\11\\144cc25aebdaeb4931b231e25fd34b394e6a5725cbb2f50106\n",
      "Successfully built kaggle\n",
      "Installing collected packages: text-unidecode, python-slugify, kaggle\n",
      "Successfully installed kaggle-1.5.12 python-slugify-6.1.2 text-unidecode-1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2411fc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading titanic.zip to C:\\Users\\KK\\Jupiter notebook\\Kaggle\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/34.1k [00:00<?, ?B/s]\n",
      "100%|##########| 34.1k/34.1k [00:00<00:00, 2.69MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e800d028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('./titanic.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "eeb50a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import optimizers, losses\n",
    "from keras.layers import Dense, Dropout, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "128483f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "3e004f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = pd.read_csv('test.csv')\n",
    "test_X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "2d43cbe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         1\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df = pd.read_csv('gender_submission.csv')\n",
    "submission_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c1aedd",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "46749ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "8372e328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId 891\n",
      "Survived 2\n",
      "Pclass 3\n",
      "Name 891\n",
      "Sex 2\n",
      "Age 89\n",
      "SibSp 7\n",
      "Parch 7\n",
      "Ticket 681\n",
      "Fare 248\n",
      "Cabin 148\n",
      "Embarked 4\n"
     ]
    }
   ],
   "source": [
    "for column in train_df.columns:\n",
    "    print(column,len(train_df[column].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "9d781916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Fare'].value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "8aecf630",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_df.drop('Survived', axis=1)\n",
    "train_Y = train_df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e773c70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = len(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "cb6d5f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                               Name  \\\n",
       "0              1       3                            Braund, Mr. Owen Harris   \n",
       "1              2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2              3       3                             Heikkinen, Miss. Laina   \n",
       "3              4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4              5       3                           Allen, Mr. William Henry   \n",
       "..           ...     ...                                                ...   \n",
       "413         1305       3                                 Spector, Mr. Woolf   \n",
       "414         1306       1                       Oliva y Ocana, Dona. Fermina   \n",
       "415         1307       3                       Saether, Mr. Simon Sivertsen   \n",
       "416         1308       3                                Ware, Mr. Frederick   \n",
       "417         1309       3                           Peter, Master. Michael J   \n",
       "\n",
       "        Sex   Age  SibSp  Parch              Ticket      Fare Cabin Embarked  \n",
       "0      male  22.0      1      0           A/5 21171    7.2500   NaN        S  \n",
       "1    female  38.0      1      0            PC 17599   71.2833   C85        C  \n",
       "2    female  26.0      0      0    STON/O2. 3101282    7.9250   NaN        S  \n",
       "3    female  35.0      1      0              113803   53.1000  C123        S  \n",
       "4      male  35.0      0      0              373450    8.0500   NaN        S  \n",
       "..      ...   ...    ...    ...                 ...       ...   ...      ...  \n",
       "413    male   NaN      0      0           A.5. 3236    8.0500   NaN        S  \n",
       "414  female  39.0      0      0            PC 17758  108.9000  C105        C  \n",
       "415    male  38.5      0      0  SOTON/O.Q. 3101262    7.2500   NaN        S  \n",
       "416    male   NaN      0      0              359309    8.0500   NaN        S  \n",
       "417    male   NaN      1      1                2668   22.3583   NaN        C  \n",
       "\n",
       "[1309 rows x 11 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.concat([train_X, test_df])\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "23ee45cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_df(df):\n",
    "    df = df.drop(['PassengerId', 'Name', 'Ticket'], axis=1)\n",
    "    \n",
    "    df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
    "    \n",
    "    df['Cabin'].fillna('N/A', inplace=True)\n",
    "\n",
    "    df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "307a00e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = preprocessing_df(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "d6f75473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1309 entries, 0 to 417\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    1309 non-null   int64  \n",
      " 1   Sex       1309 non-null   object \n",
      " 2   Age       1309 non-null   float64\n",
      " 3   SibSp     1309 non-null   int64  \n",
      " 4   Parch     1309 non-null   int64  \n",
      " 5   Fare      1308 non-null   float64\n",
      " 6   Cabin     1309 non-null   object \n",
      " 7   Embarked  1309 non-null   object \n",
      "dtypes: float64(2), int64(3), object(3)\n",
      "memory usage: 92.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>N/A</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>N/A</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass     Sex   Age  SibSp  Parch     Fare Cabin Embarked\n",
       "0       3    male  22.0      1      0   7.2500   N/A        S\n",
       "1       1  female  38.0      1      0  71.2833   C85        C\n",
       "2       3  female  26.0      0      0   7.9250   N/A        S\n",
       "3       1  female  35.0      1      0  53.1000  C123        S"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.info()\n",
    "merged_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "c75a3cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EDA(df):\n",
    "    df['Cabin'] = df['Cabin'].apply(lambda cabin : 'cabin' if cabin=='N/A' else 'not cabin')\n",
    "    df['Family'] = df.apply(lambda row : 'single' if row['SibSp'] + row['Parch'] == 0 \n",
    "                            else ('medium' if row['SibSp'] + row['Parch'] < 4 else 'large'), axis=1)\n",
    "    def trans_age(x):\n",
    "        if(x<1): x = int(str(x).split('.')[1])\n",
    "        if(x<20): return 'young'\n",
    "        if(x<60): return 'adult'\n",
    "        return 'old'\n",
    "\n",
    "    df['Age'] = df['Age'].apply(trans_age)\n",
    "    df['Fare'] = df['Fare'].apply(lambda x : 'low' if x<df['Fare'].quantile(0.25) else('medium' if x<df['Fare'].quantile(0.5) \n",
    "                                                                                   else ('high' if x<df['Fare'].quantile(0.75) \n",
    "                                                                                         else 'very high')))\n",
    "    \n",
    "    df = df.drop(['SibSp', 'Parch'], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "b32ffca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = EDA(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "3f7a36d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>adult</td>\n",
       "      <td>low</td>\n",
       "      <td>cabin</td>\n",
       "      <td>S</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>adult</td>\n",
       "      <td>very high</td>\n",
       "      <td>not cabin</td>\n",
       "      <td>C</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>adult</td>\n",
       "      <td>medium</td>\n",
       "      <td>cabin</td>\n",
       "      <td>S</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>adult</td>\n",
       "      <td>very high</td>\n",
       "      <td>not cabin</td>\n",
       "      <td>S</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>adult</td>\n",
       "      <td>medium</td>\n",
       "      <td>cabin</td>\n",
       "      <td>S</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>adult</td>\n",
       "      <td>medium</td>\n",
       "      <td>cabin</td>\n",
       "      <td>S</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>adult</td>\n",
       "      <td>very high</td>\n",
       "      <td>not cabin</td>\n",
       "      <td>C</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>adult</td>\n",
       "      <td>low</td>\n",
       "      <td>cabin</td>\n",
       "      <td>S</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>adult</td>\n",
       "      <td>medium</td>\n",
       "      <td>cabin</td>\n",
       "      <td>S</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>adult</td>\n",
       "      <td>high</td>\n",
       "      <td>cabin</td>\n",
       "      <td>C</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass     Sex    Age       Fare      Cabin Embarked  Family\n",
       "0         3    male  adult        low      cabin        S  medium\n",
       "1         1  female  adult  very high  not cabin        C  medium\n",
       "2         3  female  adult     medium      cabin        S  single\n",
       "3         1  female  adult  very high  not cabin        S  medium\n",
       "4         3    male  adult     medium      cabin        S  single\n",
       "..      ...     ...    ...        ...        ...      ...     ...\n",
       "413       3    male  adult     medium      cabin        S  single\n",
       "414       1  female  adult  very high  not cabin        C  single\n",
       "415       3    male  adult        low      cabin        S  single\n",
       "416       3    male  adult     medium      cabin        S  single\n",
       "417       3    male  adult       high      cabin        C  medium\n",
       "\n",
       "[1309 rows x 7 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "1b7a04d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Age_adult</th>\n",
       "      <th>Age_old</th>\n",
       "      <th>Age_young</th>\n",
       "      <th>Fare_high</th>\n",
       "      <th>Fare_low</th>\n",
       "      <th>Fare_medium</th>\n",
       "      <th>Fare_very high</th>\n",
       "      <th>Cabin_cabin</th>\n",
       "      <th>Cabin_not cabin</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Family_large</th>\n",
       "      <th>Family_medium</th>\n",
       "      <th>Family_single</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex_female  Sex_male  Age_adult  Age_old  Age_young  Fare_high  \\\n",
       "0         3           0         1          1        0          0          0   \n",
       "1         1           1         0          1        0          0          0   \n",
       "2         3           1         0          1        0          0          0   \n",
       "3         1           1         0          1        0          0          0   \n",
       "4         3           0         1          1        0          0          0   \n",
       "..      ...         ...       ...        ...      ...        ...        ...   \n",
       "413       3           0         1          1        0          0          0   \n",
       "414       1           1         0          1        0          0          0   \n",
       "415       3           0         1          1        0          0          0   \n",
       "416       3           0         1          1        0          0          0   \n",
       "417       3           0         1          1        0          0          1   \n",
       "\n",
       "     Fare_low  Fare_medium  Fare_very high  Cabin_cabin  Cabin_not cabin  \\\n",
       "0           1            0               0            1                0   \n",
       "1           0            0               1            0                1   \n",
       "2           0            1               0            1                0   \n",
       "3           0            0               1            0                1   \n",
       "4           0            1               0            1                0   \n",
       "..        ...          ...             ...          ...              ...   \n",
       "413         0            1               0            1                0   \n",
       "414         0            0               1            0                1   \n",
       "415         1            0               0            1                0   \n",
       "416         0            1               0            1                0   \n",
       "417         0            0               0            1                0   \n",
       "\n",
       "     Embarked_C  Embarked_Q  Embarked_S  Family_large  Family_medium  \\\n",
       "0             0           0           1             0              1   \n",
       "1             1           0           0             0              1   \n",
       "2             0           0           1             0              0   \n",
       "3             0           0           1             0              1   \n",
       "4             0           0           1             0              0   \n",
       "..          ...         ...         ...           ...            ...   \n",
       "413           0           0           1             0              0   \n",
       "414           1           0           0             0              0   \n",
       "415           0           0           1             0              0   \n",
       "416           0           0           1             0              0   \n",
       "417           1           0           0             0              1   \n",
       "\n",
       "     Family_single  \n",
       "0                0  \n",
       "1                0  \n",
       "2                1  \n",
       "3                0  \n",
       "4                1  \n",
       "..             ...  \n",
       "413              1  \n",
       "414              1  \n",
       "415              1  \n",
       "416              1  \n",
       "417              0  \n",
       "\n",
       "[1309 rows x 18 columns]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.get_dummies(merged_df)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "1968118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "merged_df = scaler.fit_transform(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "ec97426f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = merged_df[:train_size]\n",
    "test_X = merged_df[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "275420f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "801ecb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inputs = Input(shape=(features))\n",
    "    \n",
    "    x = Dense(256, activation='relu', kernel_initializer = \"he_normal\")(inputs)\n",
    "    x = Dense(128, activation='relu', kernel_initializer = \"he_normal\")(x)\n",
    "    x = Dense(64, activation='relu', kernel_initializer = \"he_normal\")(x)\n",
    "    outputs= Dense(1, activation='sigmoid', kernel_initializer = \"he_normal\")(x)\n",
    "    \n",
    "    return keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "0dbab1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 18)]              0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 256)               4864      \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 46,081\n",
      "Trainable params: 46,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "a0b857a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "eaf33d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "batch_size = 20\n",
    "validation_split = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15f045a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "2c7ea199",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_X, train_Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fd9696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "1ccb3926",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "32/32 [==============================] - 1s 9ms/step - loss: 0.5580 - accuracy: 0.7657 - val_loss: 0.4434 - val_accuracy: 0.8022\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8299 - val_loss: 0.4174 - val_accuracy: 0.8246\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8363 - val_loss: 0.4307 - val_accuracy: 0.7985\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8315 - val_loss: 0.4229 - val_accuracy: 0.8209\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3918 - accuracy: 0.8459 - val_loss: 0.4360 - val_accuracy: 0.8097\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4039 - accuracy: 0.8363 - val_loss: 0.4336 - val_accuracy: 0.8134\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3844 - accuracy: 0.8363 - val_loss: 0.4394 - val_accuracy: 0.8209\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3925 - accuracy: 0.8395 - val_loss: 0.4319 - val_accuracy: 0.8172\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3799 - accuracy: 0.8491 - val_loss: 0.4422 - val_accuracy: 0.8246\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8523 - val_loss: 0.4361 - val_accuracy: 0.8209\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3760 - accuracy: 0.8475 - val_loss: 0.4521 - val_accuracy: 0.8022\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8299 - val_loss: 0.4485 - val_accuracy: 0.8321\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8507 - val_loss: 0.4537 - val_accuracy: 0.7985\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8427 - val_loss: 0.4528 - val_accuracy: 0.8172\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3610 - accuracy: 0.8491 - val_loss: 0.4572 - val_accuracy: 0.8134\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8411 - val_loss: 0.4472 - val_accuracy: 0.8172\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3567 - accuracy: 0.8475 - val_loss: 0.4549 - val_accuracy: 0.8321\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3553 - accuracy: 0.8443 - val_loss: 0.4624 - val_accuracy: 0.8209\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3546 - accuracy: 0.8443 - val_loss: 0.4470 - val_accuracy: 0.8097\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.8587 - val_loss: 0.4873 - val_accuracy: 0.8097\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3843 - accuracy: 0.8443 - val_loss: 0.4804 - val_accuracy: 0.8022\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3562 - accuracy: 0.8459 - val_loss: 0.4493 - val_accuracy: 0.8172\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8379 - val_loss: 0.4651 - val_accuracy: 0.8097\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3502 - accuracy: 0.8571 - val_loss: 0.4472 - val_accuracy: 0.8209\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3464 - accuracy: 0.8604 - val_loss: 0.4625 - val_accuracy: 0.8134\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.8459 - val_loss: 0.4682 - val_accuracy: 0.8172\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3513 - accuracy: 0.8571 - val_loss: 0.4598 - val_accuracy: 0.8246\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.8507 - val_loss: 0.4691 - val_accuracy: 0.8358\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3503 - accuracy: 0.8571 - val_loss: 0.4771 - val_accuracy: 0.8172\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3457 - accuracy: 0.8636 - val_loss: 0.4734 - val_accuracy: 0.8246\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3460 - accuracy: 0.8587 - val_loss: 0.4597 - val_accuracy: 0.8209\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3447 - accuracy: 0.8652 - val_loss: 0.4870 - val_accuracy: 0.8172\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3450 - accuracy: 0.8571 - val_loss: 0.4789 - val_accuracy: 0.8209\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.8475 - val_loss: 0.4689 - val_accuracy: 0.8284\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3475 - accuracy: 0.8587 - val_loss: 0.4773 - val_accuracy: 0.8172\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3490 - accuracy: 0.8571 - val_loss: 0.4840 - val_accuracy: 0.8246\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.8620 - val_loss: 0.4656 - val_accuracy: 0.8321\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3403 - accuracy: 0.8539 - val_loss: 0.4765 - val_accuracy: 0.8209\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3481 - accuracy: 0.8571 - val_loss: 0.4711 - val_accuracy: 0.8284\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3397 - accuracy: 0.8587 - val_loss: 0.4807 - val_accuracy: 0.8284\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3450 - accuracy: 0.8571 - val_loss: 0.4837 - val_accuracy: 0.8246\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3417 - accuracy: 0.8587 - val_loss: 0.4818 - val_accuracy: 0.8209\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8555 - val_loss: 0.4740 - val_accuracy: 0.8284\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8539 - val_loss: 0.4861 - val_accuracy: 0.8246\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3376 - accuracy: 0.8571 - val_loss: 0.4820 - val_accuracy: 0.8209\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3362 - accuracy: 0.8491 - val_loss: 0.4813 - val_accuracy: 0.8172\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3374 - accuracy: 0.8427 - val_loss: 0.4920 - val_accuracy: 0.8284\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8555 - val_loss: 0.4911 - val_accuracy: 0.8172\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3426 - accuracy: 0.8555 - val_loss: 0.4837 - val_accuracy: 0.8209\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3390 - accuracy: 0.8507 - val_loss: 0.4944 - val_accuracy: 0.8209\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3342 - accuracy: 0.8620 - val_loss: 0.4985 - val_accuracy: 0.8209\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.8571 - val_loss: 0.4995 - val_accuracy: 0.8172\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3427 - accuracy: 0.8523 - val_loss: 0.4716 - val_accuracy: 0.8246\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.8604 - val_loss: 0.4724 - val_accuracy: 0.8209\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8620 - val_loss: 0.5106 - val_accuracy: 0.8172\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3419 - accuracy: 0.8571 - val_loss: 0.4975 - val_accuracy: 0.8209\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3346 - accuracy: 0.8491 - val_loss: 0.5097 - val_accuracy: 0.8172\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.8604 - val_loss: 0.4989 - val_accuracy: 0.8172\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3340 - accuracy: 0.8571 - val_loss: 0.4974 - val_accuracy: 0.8246\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3439 - accuracy: 0.8587 - val_loss: 0.4881 - val_accuracy: 0.8246\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3431 - accuracy: 0.8571 - val_loss: 0.5031 - val_accuracy: 0.8172\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3359 - accuracy: 0.8587 - val_loss: 0.4979 - val_accuracy: 0.8209\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3339 - accuracy: 0.8539 - val_loss: 0.4963 - val_accuracy: 0.8209\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8523 - val_loss: 0.4990 - val_accuracy: 0.8172\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8636 - val_loss: 0.5003 - val_accuracy: 0.8209\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3393 - accuracy: 0.8443 - val_loss: 0.5067 - val_accuracy: 0.8134\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3441 - accuracy: 0.8539 - val_loss: 0.4952 - val_accuracy: 0.8209\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8507 - val_loss: 0.4993 - val_accuracy: 0.8321\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8571 - val_loss: 0.5119 - val_accuracy: 0.8321\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8652 - val_loss: 0.5175 - val_accuracy: 0.8209\n",
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8604 - val_loss: 0.5164 - val_accuracy: 0.8321\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8668 - val_loss: 0.5160 - val_accuracy: 0.8209\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8636 - val_loss: 0.5210 - val_accuracy: 0.8209\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3381 - accuracy: 0.8604 - val_loss: 0.5118 - val_accuracy: 0.8172\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8604 - val_loss: 0.5259 - val_accuracy: 0.8209\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8571 - val_loss: 0.5308 - val_accuracy: 0.8209\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8507 - val_loss: 0.5354 - val_accuracy: 0.8172\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3255 - accuracy: 0.8604 - val_loss: 0.5345 - val_accuracy: 0.8172\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3247 - accuracy: 0.8620 - val_loss: 0.5396 - val_accuracy: 0.8209\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8604 - val_loss: 0.5491 - val_accuracy: 0.8172\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8555 - val_loss: 0.5439 - val_accuracy: 0.8209\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3251 - accuracy: 0.8587 - val_loss: 0.5354 - val_accuracy: 0.8209\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8587 - val_loss: 0.5557 - val_accuracy: 0.8172\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8507 - val_loss: 0.5373 - val_accuracy: 0.8246\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8587 - val_loss: 0.5363 - val_accuracy: 0.8172\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3240 - accuracy: 0.8587 - val_loss: 0.5440 - val_accuracy: 0.8209\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3240 - accuracy: 0.8668 - val_loss: 0.5513 - val_accuracy: 0.8172\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8587 - val_loss: 0.5512 - val_accuracy: 0.8172\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8587 - val_loss: 0.5478 - val_accuracy: 0.8284\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8555 - val_loss: 0.5672 - val_accuracy: 0.8134\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3328 - accuracy: 0.8571 - val_loss: 0.5282 - val_accuracy: 0.8172\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8555 - val_loss: 0.5197 - val_accuracy: 0.8209\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8587 - val_loss: 0.5331 - val_accuracy: 0.8172\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.8620 - val_loss: 0.5458 - val_accuracy: 0.8172\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8620 - val_loss: 0.5433 - val_accuracy: 0.8134\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8571 - val_loss: 0.5510 - val_accuracy: 0.8097\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8587 - val_loss: 0.5526 - val_accuracy: 0.8134\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3242 - accuracy: 0.8571 - val_loss: 0.5366 - val_accuracy: 0.8284\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8604 - val_loss: 0.5414 - val_accuracy: 0.8284\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3212 - accuracy: 0.8587 - val_loss: 0.5549 - val_accuracy: 0.8321\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8636 - val_loss: 0.5496 - val_accuracy: 0.8321\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3223 - accuracy: 0.8652 - val_loss: 0.5534 - val_accuracy: 0.8209\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3196 - accuracy: 0.8652 - val_loss: 0.5638 - val_accuracy: 0.8284\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3225 - accuracy: 0.8636 - val_loss: 0.5605 - val_accuracy: 0.8284\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.8587 - val_loss: 0.5650 - val_accuracy: 0.8321\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3215 - accuracy: 0.8652 - val_loss: 0.5614 - val_accuracy: 0.8246\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3215 - accuracy: 0.8636 - val_loss: 0.5687 - val_accuracy: 0.8134\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3258 - accuracy: 0.8491 - val_loss: 0.5577 - val_accuracy: 0.8246\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8636 - val_loss: 0.5510 - val_accuracy: 0.8209\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3219 - accuracy: 0.8604 - val_loss: 0.5818 - val_accuracy: 0.8209\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.8571 - val_loss: 0.5625 - val_accuracy: 0.8284\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3225 - accuracy: 0.8636 - val_loss: 0.5641 - val_accuracy: 0.8284\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8620 - val_loss: 0.5466 - val_accuracy: 0.8284\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3247 - accuracy: 0.8587 - val_loss: 0.5729 - val_accuracy: 0.8209\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3197 - accuracy: 0.8539 - val_loss: 0.5727 - val_accuracy: 0.8209\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3223 - accuracy: 0.8571 - val_loss: 0.5687 - val_accuracy: 0.8246\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3207 - accuracy: 0.8604 - val_loss: 0.5561 - val_accuracy: 0.8246\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8587 - val_loss: 0.5568 - val_accuracy: 0.8209\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3245 - accuracy: 0.8555 - val_loss: 0.5590 - val_accuracy: 0.8284\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8523 - val_loss: 0.5497 - val_accuracy: 0.8246\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 0.8571 - val_loss: 0.5627 - val_accuracy: 0.8246\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.8571 - val_loss: 0.5599 - val_accuracy: 0.8246\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3199 - accuracy: 0.8652 - val_loss: 0.5692 - val_accuracy: 0.8284\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3203 - accuracy: 0.8636 - val_loss: 0.5846 - val_accuracy: 0.8284\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3245 - accuracy: 0.8652 - val_loss: 0.5574 - val_accuracy: 0.8209\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8652 - val_loss: 0.5511 - val_accuracy: 0.8246\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3255 - accuracy: 0.8604 - val_loss: 0.5555 - val_accuracy: 0.8209\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8587 - val_loss: 0.5692 - val_accuracy: 0.8209\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3196 - accuracy: 0.8587 - val_loss: 0.5767 - val_accuracy: 0.8246\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3190 - accuracy: 0.8620 - val_loss: 0.5764 - val_accuracy: 0.8209\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3196 - accuracy: 0.8620 - val_loss: 0.5912 - val_accuracy: 0.8209\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3198 - accuracy: 0.8652 - val_loss: 0.5835 - val_accuracy: 0.8284\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3240 - accuracy: 0.8604 - val_loss: 0.5673 - val_accuracy: 0.8246\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3212 - accuracy: 0.8571 - val_loss: 0.5648 - val_accuracy: 0.8209\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3224 - accuracy: 0.8652 - val_loss: 0.5669 - val_accuracy: 0.8246\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3180 - accuracy: 0.8604 - val_loss: 0.5837 - val_accuracy: 0.8209\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3177 - accuracy: 0.8587 - val_loss: 0.5812 - val_accuracy: 0.8284\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3211 - accuracy: 0.8668 - val_loss: 0.5762 - val_accuracy: 0.8246\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3219 - accuracy: 0.8587 - val_loss: 0.5895 - val_accuracy: 0.8246\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3167 - accuracy: 0.8620 - val_loss: 0.6067 - val_accuracy: 0.8284\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3181 - accuracy: 0.8668 - val_loss: 0.5975 - val_accuracy: 0.8284\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3193 - accuracy: 0.8668 - val_loss: 0.6140 - val_accuracy: 0.8246\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3180 - accuracy: 0.8620 - val_loss: 0.6135 - val_accuracy: 0.8284\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3207 - accuracy: 0.8636 - val_loss: 0.6103 - val_accuracy: 0.8246\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.8587 - val_loss: 0.6097 - val_accuracy: 0.8284\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3173 - accuracy: 0.8636 - val_loss: 0.6202 - val_accuracy: 0.8246\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3209 - accuracy: 0.8604 - val_loss: 0.6248 - val_accuracy: 0.8246\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8652 - val_loss: 0.6117 - val_accuracy: 0.8246\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8571 - val_loss: 0.6161 - val_accuracy: 0.8284\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3194 - accuracy: 0.8636 - val_loss: 0.5963 - val_accuracy: 0.8284\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3201 - accuracy: 0.8636 - val_loss: 0.6126 - val_accuracy: 0.8284\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3179 - accuracy: 0.8587 - val_loss: 0.6186 - val_accuracy: 0.8284\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3161 - accuracy: 0.8587 - val_loss: 0.6214 - val_accuracy: 0.8284\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3169 - accuracy: 0.8652 - val_loss: 0.6184 - val_accuracy: 0.8284\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3153 - accuracy: 0.8636 - val_loss: 0.6174 - val_accuracy: 0.8284\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3144 - accuracy: 0.8652 - val_loss: 0.6237 - val_accuracy: 0.8246\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3166 - accuracy: 0.8668 - val_loss: 0.6245 - val_accuracy: 0.8284\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3171 - accuracy: 0.8652 - val_loss: 0.6313 - val_accuracy: 0.8284\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3188 - accuracy: 0.8652 - val_loss: 0.6356 - val_accuracy: 0.8284\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3194 - accuracy: 0.8620 - val_loss: 0.6414 - val_accuracy: 0.8284\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3177 - accuracy: 0.8652 - val_loss: 0.6446 - val_accuracy: 0.8284\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3148 - accuracy: 0.8652 - val_loss: 0.6359 - val_accuracy: 0.8284\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3156 - accuracy: 0.8620 - val_loss: 0.6447 - val_accuracy: 0.8284\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3144 - accuracy: 0.8652 - val_loss: 0.6578 - val_accuracy: 0.8246\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3160 - accuracy: 0.8668 - val_loss: 0.6530 - val_accuracy: 0.8284\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3161 - accuracy: 0.8620 - val_loss: 0.6368 - val_accuracy: 0.8284\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3159 - accuracy: 0.8652 - val_loss: 0.6530 - val_accuracy: 0.8284\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3138 - accuracy: 0.8604 - val_loss: 0.6599 - val_accuracy: 0.8246\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3158 - accuracy: 0.8652 - val_loss: 0.6685 - val_accuracy: 0.8284\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3135 - accuracy: 0.8652 - val_loss: 0.6700 - val_accuracy: 0.8284\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3143 - accuracy: 0.8636 - val_loss: 0.6797 - val_accuracy: 0.8284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3150 - accuracy: 0.8636 - val_loss: 0.6740 - val_accuracy: 0.8284\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3147 - accuracy: 0.8652 - val_loss: 0.6823 - val_accuracy: 0.8284\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3142 - accuracy: 0.8636 - val_loss: 0.6953 - val_accuracy: 0.8284\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3210 - accuracy: 0.8604 - val_loss: 0.6668 - val_accuracy: 0.8284\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3184 - accuracy: 0.8620 - val_loss: 0.6504 - val_accuracy: 0.8284\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3192 - accuracy: 0.8636 - val_loss: 0.6587 - val_accuracy: 0.8284\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3167 - accuracy: 0.8636 - val_loss: 0.6493 - val_accuracy: 0.8284\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3187 - accuracy: 0.8604 - val_loss: 0.6350 - val_accuracy: 0.8284\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3189 - accuracy: 0.8652 - val_loss: 0.6539 - val_accuracy: 0.8284\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.8652 - val_loss: 0.6577 - val_accuracy: 0.8284\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3207 - accuracy: 0.8636 - val_loss: 0.6492 - val_accuracy: 0.8246\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3151 - accuracy: 0.8668 - val_loss: 0.6502 - val_accuracy: 0.8284\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3170 - accuracy: 0.8604 - val_loss: 0.6612 - val_accuracy: 0.8246\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3148 - accuracy: 0.8636 - val_loss: 0.6474 - val_accuracy: 0.8284\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3140 - accuracy: 0.8652 - val_loss: 0.6499 - val_accuracy: 0.8284\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3137 - accuracy: 0.8652 - val_loss: 0.6711 - val_accuracy: 0.8246\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3171 - accuracy: 0.8636 - val_loss: 0.6385 - val_accuracy: 0.8284\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3149 - accuracy: 0.8652 - val_loss: 0.6531 - val_accuracy: 0.8284\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3242 - accuracy: 0.8587 - val_loss: 0.6760 - val_accuracy: 0.8284\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3188 - accuracy: 0.8571 - val_loss: 0.6390 - val_accuracy: 0.8246\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3155 - accuracy: 0.8652 - val_loss: 0.6405 - val_accuracy: 0.8284\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3146 - accuracy: 0.8620 - val_loss: 0.6631 - val_accuracy: 0.8284\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.8636 - val_loss: 0.6801 - val_accuracy: 0.8246\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3184 - accuracy: 0.8636 - val_loss: 0.6564 - val_accuracy: 0.8284\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3157 - accuracy: 0.8668 - val_loss: 0.6457 - val_accuracy: 0.8284\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3175 - accuracy: 0.8571 - val_loss: 0.6546 - val_accuracy: 0.8284\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3171 - accuracy: 0.8652 - val_loss: 0.6484 - val_accuracy: 0.8284\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3164 - accuracy: 0.8620 - val_loss: 0.6514 - val_accuracy: 0.8284\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.8636 - val_loss: 0.6578 - val_accuracy: 0.8284\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3169 - accuracy: 0.8652 - val_loss: 0.6687 - val_accuracy: 0.8284\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3130 - accuracy: 0.8636 - val_loss: 0.6829 - val_accuracy: 0.8284\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.8652 - val_loss: 0.6812 - val_accuracy: 0.8284\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3143 - accuracy: 0.8652 - val_loss: 0.6804 - val_accuracy: 0.8284\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3140 - accuracy: 0.8652 - val_loss: 0.6720 - val_accuracy: 0.8284\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3172 - accuracy: 0.8636 - val_loss: 0.6705 - val_accuracy: 0.8284\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.8620 - val_loss: 0.6742 - val_accuracy: 0.8209\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3147 - accuracy: 0.8652 - val_loss: 0.6839 - val_accuracy: 0.8246\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3153 - accuracy: 0.8652 - val_loss: 0.6770 - val_accuracy: 0.8246\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3165 - accuracy: 0.8636 - val_loss: 0.6728 - val_accuracy: 0.8284\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3158 - accuracy: 0.8620 - val_loss: 0.6879 - val_accuracy: 0.8284\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3169 - accuracy: 0.8587 - val_loss: 0.6863 - val_accuracy: 0.8284\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3141 - accuracy: 0.8636 - val_loss: 0.6667 - val_accuracy: 0.8246\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 0.8620 - val_loss: 0.6640 - val_accuracy: 0.8246\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3138 - accuracy: 0.8620 - val_loss: 0.6671 - val_accuracy: 0.8246\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 0.8604 - val_loss: 0.6656 - val_accuracy: 0.8284\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3197 - accuracy: 0.8604 - val_loss: 0.6576 - val_accuracy: 0.8284\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.8668 - val_loss: 0.6601 - val_accuracy: 0.8284\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3128 - accuracy: 0.8668 - val_loss: 0.6788 - val_accuracy: 0.8284\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.8620 - val_loss: 0.6842 - val_accuracy: 0.8284\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3197 - accuracy: 0.8587 - val_loss: 0.6875 - val_accuracy: 0.8209\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8668 - val_loss: 0.6870 - val_accuracy: 0.8246\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3183 - accuracy: 0.8636 - val_loss: 0.6840 - val_accuracy: 0.8246\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3158 - accuracy: 0.8620 - val_loss: 0.6815 - val_accuracy: 0.8246\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3149 - accuracy: 0.8604 - val_loss: 0.6893 - val_accuracy: 0.8246\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3157 - accuracy: 0.8620 - val_loss: 0.7066 - val_accuracy: 0.8246\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3161 - accuracy: 0.8652 - val_loss: 0.6990 - val_accuracy: 0.8246\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3146 - accuracy: 0.8620 - val_loss: 0.7079 - val_accuracy: 0.8246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3122 - accuracy: 0.8636 - val_loss: 0.7059 - val_accuracy: 0.8246\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.8587 - val_loss: 0.7096 - val_accuracy: 0.8246\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3130 - accuracy: 0.8620 - val_loss: 0.7082 - val_accuracy: 0.8246\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.8604 - val_loss: 0.6923 - val_accuracy: 0.8284\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.8587 - val_loss: 0.6841 - val_accuracy: 0.8209\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3137 - accuracy: 0.8636 - val_loss: 0.7081 - val_accuracy: 0.8284\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3130 - accuracy: 0.8652 - val_loss: 0.7109 - val_accuracy: 0.8246\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3149 - accuracy: 0.8652 - val_loss: 0.7137 - val_accuracy: 0.8284\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3142 - accuracy: 0.8652 - val_loss: 0.7189 - val_accuracy: 0.8284\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3140 - accuracy: 0.8636 - val_loss: 0.7189 - val_accuracy: 0.8284\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3128 - accuracy: 0.8668 - val_loss: 0.7068 - val_accuracy: 0.8246\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3156 - accuracy: 0.8668 - val_loss: 0.7136 - val_accuracy: 0.8246\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3169 - accuracy: 0.8668 - val_loss: 0.7337 - val_accuracy: 0.8246\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3139 - accuracy: 0.8668 - val_loss: 0.7289 - val_accuracy: 0.8284\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3160 - accuracy: 0.8636 - val_loss: 0.7227 - val_accuracy: 0.8284\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3122 - accuracy: 0.8652 - val_loss: 0.6865 - val_accuracy: 0.8246\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.8604 - val_loss: 0.7165 - val_accuracy: 0.8284\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3132 - accuracy: 0.8652 - val_loss: 0.7273 - val_accuracy: 0.8284\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3163 - accuracy: 0.8636 - val_loss: 0.7158 - val_accuracy: 0.8284\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.8668 - val_loss: 0.7195 - val_accuracy: 0.8284\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3142 - accuracy: 0.8668 - val_loss: 0.7048 - val_accuracy: 0.8284\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3130 - accuracy: 0.8668 - val_loss: 0.7082 - val_accuracy: 0.8284\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.8652 - val_loss: 0.7297 - val_accuracy: 0.8284\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3150 - accuracy: 0.8652 - val_loss: 0.7397 - val_accuracy: 0.8284\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.8652 - val_loss: 0.7306 - val_accuracy: 0.8284\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8668 - val_loss: 0.7408 - val_accuracy: 0.8284\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.8684 - val_loss: 0.7447 - val_accuracy: 0.8246\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3141 - accuracy: 0.8636 - val_loss: 0.7441 - val_accuracy: 0.8284\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.8620 - val_loss: 0.7381 - val_accuracy: 0.8284\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8636 - val_loss: 0.7298 - val_accuracy: 0.8284\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3128 - accuracy: 0.8652 - val_loss: 0.7259 - val_accuracy: 0.8284\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8604 - val_loss: 0.7390 - val_accuracy: 0.8284\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3135 - accuracy: 0.8604 - val_loss: 0.7327 - val_accuracy: 0.8246\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.8652 - val_loss: 0.7387 - val_accuracy: 0.8284\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3147 - accuracy: 0.8652 - val_loss: 0.7292 - val_accuracy: 0.8246\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3126 - accuracy: 0.8604 - val_loss: 0.7096 - val_accuracy: 0.8246\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3162 - accuracy: 0.8604 - val_loss: 0.7185 - val_accuracy: 0.8246\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3143 - accuracy: 0.8620 - val_loss: 0.7174 - val_accuracy: 0.8284\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3159 - accuracy: 0.8652 - val_loss: 0.7194 - val_accuracy: 0.8284\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3131 - accuracy: 0.8652 - val_loss: 0.7323 - val_accuracy: 0.8321\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3121 - accuracy: 0.8604 - val_loss: 0.7525 - val_accuracy: 0.8284\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3126 - accuracy: 0.8636 - val_loss: 0.7499 - val_accuracy: 0.8246\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.8636 - val_loss: 0.7647 - val_accuracy: 0.8284\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.8555 - val_loss: 0.7687 - val_accuracy: 0.8246\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3116 - accuracy: 0.8668 - val_loss: 0.7748 - val_accuracy: 0.8284\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 0.8652 - val_loss: 0.7102 - val_accuracy: 0.8209\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.8620 - val_loss: 0.7008 - val_accuracy: 0.8246\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3128 - accuracy: 0.8604 - val_loss: 0.7129 - val_accuracy: 0.8284\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.8636 - val_loss: 0.7219 - val_accuracy: 0.8284\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3134 - accuracy: 0.8652 - val_loss: 0.7287 - val_accuracy: 0.8284\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3126 - accuracy: 0.8668 - val_loss: 0.7500 - val_accuracy: 0.8246\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3128 - accuracy: 0.8652 - val_loss: 0.7470 - val_accuracy: 0.8246\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3148 - accuracy: 0.8620 - val_loss: 0.7345 - val_accuracy: 0.8246\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3141 - accuracy: 0.8652 - val_loss: 0.7312 - val_accuracy: 0.8246\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8668 - val_loss: 0.7464 - val_accuracy: 0.8246\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3116 - accuracy: 0.8652 - val_loss: 0.7530 - val_accuracy: 0.8246\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3116 - accuracy: 0.8620 - val_loss: 0.7537 - val_accuracy: 0.8246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.8652 - val_loss: 0.7730 - val_accuracy: 0.8246\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3116 - accuracy: 0.8668 - val_loss: 0.7638 - val_accuracy: 0.8246\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3147 - accuracy: 0.8636 - val_loss: 0.7585 - val_accuracy: 0.8246\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3122 - accuracy: 0.8587 - val_loss: 0.7661 - val_accuracy: 0.8284\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3118 - accuracy: 0.8668 - val_loss: 0.7609 - val_accuracy: 0.8246\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3119 - accuracy: 0.8652 - val_loss: 0.7390 - val_accuracy: 0.8246\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.8668 - val_loss: 0.7541 - val_accuracy: 0.8284\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3139 - accuracy: 0.8620 - val_loss: 0.7568 - val_accuracy: 0.8246\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8652 - val_loss: 0.7632 - val_accuracy: 0.8284\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3138 - accuracy: 0.8668 - val_loss: 0.7624 - val_accuracy: 0.8246\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.8668 - val_loss: 0.7899 - val_accuracy: 0.8246\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3116 - accuracy: 0.8636 - val_loss: 0.7883 - val_accuracy: 0.8246\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.8636 - val_loss: 0.7957 - val_accuracy: 0.8246\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3141 - accuracy: 0.8652 - val_loss: 0.7909 - val_accuracy: 0.8284\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.8668 - val_loss: 0.7680 - val_accuracy: 0.8284\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3104 - accuracy: 0.8668 - val_loss: 0.7796 - val_accuracy: 0.8284\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3118 - accuracy: 0.8636 - val_loss: 0.7854 - val_accuracy: 0.8284\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3105 - accuracy: 0.8668 - val_loss: 0.7932 - val_accuracy: 0.8284\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3118 - accuracy: 0.8636 - val_loss: 0.8080 - val_accuracy: 0.8284\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3161 - accuracy: 0.8652 - val_loss: 0.8074 - val_accuracy: 0.8246\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.8668 - val_loss: 0.7666 - val_accuracy: 0.8321\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3128 - accuracy: 0.8652 - val_loss: 0.7929 - val_accuracy: 0.8321\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3159 - accuracy: 0.8604 - val_loss: 0.7763 - val_accuracy: 0.8358\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.8652 - val_loss: 0.7946 - val_accuracy: 0.8284\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3131 - accuracy: 0.8652 - val_loss: 0.7982 - val_accuracy: 0.8284\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.8668 - val_loss: 0.8008 - val_accuracy: 0.8284\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3141 - accuracy: 0.8652 - val_loss: 0.7950 - val_accuracy: 0.8284\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.8652 - val_loss: 0.7970 - val_accuracy: 0.8284\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.8652 - val_loss: 0.7766 - val_accuracy: 0.8284\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3116 - accuracy: 0.8652 - val_loss: 0.7899 - val_accuracy: 0.8284\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.8636 - val_loss: 0.7960 - val_accuracy: 0.8284\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8652 - val_loss: 0.7973 - val_accuracy: 0.8284\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.8636 - val_loss: 0.7972 - val_accuracy: 0.8284\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.8668 - val_loss: 0.7968 - val_accuracy: 0.8284\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3120 - accuracy: 0.8668 - val_loss: 0.8037 - val_accuracy: 0.8284\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.8652 - val_loss: 0.8079 - val_accuracy: 0.8284\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3113 - accuracy: 0.8636 - val_loss: 0.7903 - val_accuracy: 0.8284\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3099 - accuracy: 0.8636 - val_loss: 0.8076 - val_accuracy: 0.8321\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.8620 - val_loss: 0.8201 - val_accuracy: 0.8246\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.8652 - val_loss: 0.8307 - val_accuracy: 0.8284\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3113 - accuracy: 0.8684 - val_loss: 0.8229 - val_accuracy: 0.8284\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3099 - accuracy: 0.8636 - val_loss: 0.7906 - val_accuracy: 0.8284\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.8636 - val_loss: 0.8095 - val_accuracy: 0.8284\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.8604 - val_loss: 0.7997 - val_accuracy: 0.8284\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3126 - accuracy: 0.8620 - val_loss: 0.7875 - val_accuracy: 0.8284\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3135 - accuracy: 0.8668 - val_loss: 0.7858 - val_accuracy: 0.8284\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8652 - val_loss: 0.8124 - val_accuracy: 0.8284\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3118 - accuracy: 0.8668 - val_loss: 0.8199 - val_accuracy: 0.8284\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3120 - accuracy: 0.8636 - val_loss: 0.8089 - val_accuracy: 0.8246\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3118 - accuracy: 0.8668 - val_loss: 0.8241 - val_accuracy: 0.8284\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3099 - accuracy: 0.8636 - val_loss: 0.8379 - val_accuracy: 0.8284\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8668 - val_loss: 0.8499 - val_accuracy: 0.8321\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.8636 - val_loss: 0.8534 - val_accuracy: 0.8321\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.8652 - val_loss: 0.8456 - val_accuracy: 0.8321\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3100 - accuracy: 0.8668 - val_loss: 0.8425 - val_accuracy: 0.8321\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.8636 - val_loss: 0.8523 - val_accuracy: 0.8284\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8652 - val_loss: 0.8535 - val_accuracy: 0.8321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.8636 - val_loss: 0.8585 - val_accuracy: 0.8284\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3122 - accuracy: 0.8636 - val_loss: 0.8619 - val_accuracy: 0.8284\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3116 - accuracy: 0.8620 - val_loss: 0.8562 - val_accuracy: 0.8284\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8620 - val_loss: 0.8551 - val_accuracy: 0.8284\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.8668 - val_loss: 0.8480 - val_accuracy: 0.8321\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8652 - val_loss: 0.8587 - val_accuracy: 0.8321\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8636 - val_loss: 0.8654 - val_accuracy: 0.8284\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.8652 - val_loss: 0.8664 - val_accuracy: 0.8284\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8652 - val_loss: 0.8685 - val_accuracy: 0.8321\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.8636 - val_loss: 0.8785 - val_accuracy: 0.8321\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3112 - accuracy: 0.8620 - val_loss: 0.8814 - val_accuracy: 0.8321\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3095 - accuracy: 0.8652 - val_loss: 0.8822 - val_accuracy: 0.8321\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3105 - accuracy: 0.8636 - val_loss: 0.8822 - val_accuracy: 0.8284\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8652 - val_loss: 0.8887 - val_accuracy: 0.8321\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8636 - val_loss: 0.8841 - val_accuracy: 0.8358\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3101 - accuracy: 0.8620 - val_loss: 0.8855 - val_accuracy: 0.8321\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.8636 - val_loss: 0.8750 - val_accuracy: 0.8321\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8652 - val_loss: 0.9047 - val_accuracy: 0.8321\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.8604 - val_loss: 0.8389 - val_accuracy: 0.8321\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.8636 - val_loss: 0.8295 - val_accuracy: 0.8321\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.8668 - val_loss: 0.8072 - val_accuracy: 0.8321\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3160 - accuracy: 0.8652 - val_loss: 0.8330 - val_accuracy: 0.8284\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8636 - val_loss: 0.8327 - val_accuracy: 0.8284\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3119 - accuracy: 0.8636 - val_loss: 0.8300 - val_accuracy: 0.8321\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8636 - val_loss: 0.7973 - val_accuracy: 0.8321\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8668 - val_loss: 0.8044 - val_accuracy: 0.8321\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8668 - val_loss: 0.8190 - val_accuracy: 0.8321\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.8652 - val_loss: 0.8238 - val_accuracy: 0.8321\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.8604 - val_loss: 0.8392 - val_accuracy: 0.8321\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3119 - accuracy: 0.8652 - val_loss: 0.8299 - val_accuracy: 0.8321\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3122 - accuracy: 0.8668 - val_loss: 0.8281 - val_accuracy: 0.8321\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3120 - accuracy: 0.8652 - val_loss: 0.8249 - val_accuracy: 0.8321\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.8652 - val_loss: 0.8389 - val_accuracy: 0.8321\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.8620 - val_loss: 0.8325 - val_accuracy: 0.8284\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.8652 - val_loss: 0.8271 - val_accuracy: 0.8284\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8668 - val_loss: 0.8228 - val_accuracy: 0.8321\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3105 - accuracy: 0.8636 - val_loss: 0.8376 - val_accuracy: 0.8321\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.8652 - val_loss: 0.8430 - val_accuracy: 0.8321\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8668 - val_loss: 0.8429 - val_accuracy: 0.8321\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8652 - val_loss: 0.8449 - val_accuracy: 0.8284\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3143 - accuracy: 0.8620 - val_loss: 0.8282 - val_accuracy: 0.8284\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.8636 - val_loss: 0.8024 - val_accuracy: 0.8284\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3101 - accuracy: 0.8620 - val_loss: 0.7933 - val_accuracy: 0.8284\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.8652 - val_loss: 0.8243 - val_accuracy: 0.8284\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3128 - accuracy: 0.8636 - val_loss: 0.8338 - val_accuracy: 0.8284\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8652 - val_loss: 0.8434 - val_accuracy: 0.8284\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.8604 - val_loss: 0.8226 - val_accuracy: 0.8284\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3113 - accuracy: 0.8652 - val_loss: 0.8453 - val_accuracy: 0.8284\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.8668 - val_loss: 0.8681 - val_accuracy: 0.8284\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8620 - val_loss: 0.8764 - val_accuracy: 0.8284\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8668 - val_loss: 0.8806 - val_accuracy: 0.8284\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3101 - accuracy: 0.8636 - val_loss: 0.8941 - val_accuracy: 0.8284\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3104 - accuracy: 0.8652 - val_loss: 0.8957 - val_accuracy: 0.8284\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8652 - val_loss: 0.8934 - val_accuracy: 0.8284\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8636 - val_loss: 0.9068 - val_accuracy: 0.8284\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.8652 - val_loss: 0.8964 - val_accuracy: 0.8284\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3113 - accuracy: 0.8620 - val_loss: 0.8957 - val_accuracy: 0.8284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.8604 - val_loss: 0.9086 - val_accuracy: 0.8284\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3126 - accuracy: 0.8668 - val_loss: 0.8871 - val_accuracy: 0.8284\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3177 - accuracy: 0.8668 - val_loss: 0.8609 - val_accuracy: 0.8246\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3112 - accuracy: 0.8652 - val_loss: 0.8688 - val_accuracy: 0.8284\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.8668 - val_loss: 0.9103 - val_accuracy: 0.8321\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.8636 - val_loss: 0.8568 - val_accuracy: 0.8284\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3100 - accuracy: 0.8636 - val_loss: 0.8962 - val_accuracy: 0.8284\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8636 - val_loss: 0.8885 - val_accuracy: 0.8284\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8620 - val_loss: 0.8946 - val_accuracy: 0.8284\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3099 - accuracy: 0.8652 - val_loss: 0.9044 - val_accuracy: 0.8284\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8668 - val_loss: 0.8981 - val_accuracy: 0.8284\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8668 - val_loss: 0.9055 - val_accuracy: 0.8246\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.8652 - val_loss: 0.9307 - val_accuracy: 0.8321\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8668 - val_loss: 0.7858 - val_accuracy: 0.8284\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.8668 - val_loss: 0.7902 - val_accuracy: 0.8321\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.8652 - val_loss: 0.8193 - val_accuracy: 0.8284\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.8668 - val_loss: 0.8059 - val_accuracy: 0.8284\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8636 - val_loss: 0.8095 - val_accuracy: 0.8246\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3118 - accuracy: 0.8652 - val_loss: 0.8146 - val_accuracy: 0.8284\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8620 - val_loss: 0.8261 - val_accuracy: 0.8284\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8668 - val_loss: 0.8250 - val_accuracy: 0.8284\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.8668 - val_loss: 0.8387 - val_accuracy: 0.8284\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8668 - val_loss: 0.8322 - val_accuracy: 0.8284\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3113 - accuracy: 0.8668 - val_loss: 0.8485 - val_accuracy: 0.8284\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3135 - accuracy: 0.8668 - val_loss: 0.8753 - val_accuracy: 0.8284\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.8652 - val_loss: 0.9118 - val_accuracy: 0.8321\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3984 - accuracy: 0.8507 - val_loss: 0.7917 - val_accuracy: 0.8284\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3253 - accuracy: 0.8571 - val_loss: 0.8139 - val_accuracy: 0.8246\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3217 - accuracy: 0.8620 - val_loss: 0.7685 - val_accuracy: 0.8246\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3141 - accuracy: 0.8652 - val_loss: 0.8002 - val_accuracy: 0.8284\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.8668 - val_loss: 0.8289 - val_accuracy: 0.8246\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3122 - accuracy: 0.8668 - val_loss: 0.8281 - val_accuracy: 0.8246\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3137 - accuracy: 0.8652 - val_loss: 0.8250 - val_accuracy: 0.8284\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.8652 - val_loss: 0.8309 - val_accuracy: 0.8246\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8636 - val_loss: 0.8469 - val_accuracy: 0.8246\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8636 - val_loss: 0.8392 - val_accuracy: 0.8246\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8604 - val_loss: 0.8422 - val_accuracy: 0.8246\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.8636 - val_loss: 0.8485 - val_accuracy: 0.8246\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.8620 - val_loss: 0.8497 - val_accuracy: 0.8246\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.8620 - val_loss: 0.8519 - val_accuracy: 0.8246\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.8620 - val_loss: 0.8564 - val_accuracy: 0.8209\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8571 - val_loss: 0.8540 - val_accuracy: 0.8246\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8652 - val_loss: 0.8520 - val_accuracy: 0.8246\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.8620 - val_loss: 0.8420 - val_accuracy: 0.8209\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.8652 - val_loss: 0.8454 - val_accuracy: 0.8246\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8636 - val_loss: 0.8530 - val_accuracy: 0.8246\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3099 - accuracy: 0.8652 - val_loss: 0.8586 - val_accuracy: 0.8246\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.8652 - val_loss: 0.8650 - val_accuracy: 0.8209\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8652 - val_loss: 0.8597 - val_accuracy: 0.8246\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3126 - accuracy: 0.8652 - val_loss: 0.8710 - val_accuracy: 0.8284\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8604 - val_loss: 0.8753 - val_accuracy: 0.8246\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8652 - val_loss: 0.8843 - val_accuracy: 0.8246\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8652 - val_loss: 0.8872 - val_accuracy: 0.8284\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8668 - val_loss: 0.8846 - val_accuracy: 0.8284\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3101 - accuracy: 0.8636 - val_loss: 0.8938 - val_accuracy: 0.8284\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8604 - val_loss: 0.8857 - val_accuracy: 0.8246\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8636 - val_loss: 0.8845 - val_accuracy: 0.8284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.8636 - val_loss: 0.8940 - val_accuracy: 0.8284\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8668 - val_loss: 0.8759 - val_accuracy: 0.8246\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8636 - val_loss: 0.8801 - val_accuracy: 0.8246\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3105 - accuracy: 0.8652 - val_loss: 0.8850 - val_accuracy: 0.8246\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8636 - val_loss: 0.8881 - val_accuracy: 0.8284\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8604 - val_loss: 0.8914 - val_accuracy: 0.8246\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8668 - val_loss: 0.8974 - val_accuracy: 0.8284\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8652 - val_loss: 0.8950 - val_accuracy: 0.8284\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8668 - val_loss: 0.9007 - val_accuracy: 0.8284\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3105 - accuracy: 0.8652 - val_loss: 0.8970 - val_accuracy: 0.8284\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8636 - val_loss: 0.8915 - val_accuracy: 0.8284\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8668 - val_loss: 0.8940 - val_accuracy: 0.8246\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.8668 - val_loss: 0.8854 - val_accuracy: 0.8246\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3112 - accuracy: 0.8668 - val_loss: 0.8814 - val_accuracy: 0.8246\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3101 - accuracy: 0.8652 - val_loss: 0.8845 - val_accuracy: 0.8284\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8652 - val_loss: 0.8824 - val_accuracy: 0.8284\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8636 - val_loss: 0.8964 - val_accuracy: 0.8284\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8620 - val_loss: 0.8938 - val_accuracy: 0.8284\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8636 - val_loss: 0.9126 - val_accuracy: 0.8246\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3140 - accuracy: 0.8652 - val_loss: 0.8964 - val_accuracy: 0.8246\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8668 - val_loss: 0.8664 - val_accuracy: 0.8284\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.8636 - val_loss: 0.8611 - val_accuracy: 0.8284\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3095 - accuracy: 0.8636 - val_loss: 0.8549 - val_accuracy: 0.8284\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8668 - val_loss: 0.8516 - val_accuracy: 0.8284\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8652 - val_loss: 0.8793 - val_accuracy: 0.8284\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8636 - val_loss: 0.8847 - val_accuracy: 0.8284\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8620 - val_loss: 0.8930 - val_accuracy: 0.8284\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3099 - accuracy: 0.8652 - val_loss: 0.9037 - val_accuracy: 0.8172\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.8636 - val_loss: 0.8094 - val_accuracy: 0.8284\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8652 - val_loss: 0.8336 - val_accuracy: 0.8284\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8620 - val_loss: 0.8368 - val_accuracy: 0.8246\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8636 - val_loss: 0.8384 - val_accuracy: 0.8321\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3112 - accuracy: 0.8620 - val_loss: 0.8570 - val_accuracy: 0.8284\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8652 - val_loss: 0.8559 - val_accuracy: 0.8284\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.8620 - val_loss: 0.8622 - val_accuracy: 0.8246\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8668 - val_loss: 0.8693 - val_accuracy: 0.8284\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3101 - accuracy: 0.8668 - val_loss: 0.8746 - val_accuracy: 0.8284\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8668 - val_loss: 0.8839 - val_accuracy: 0.8284\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3112 - accuracy: 0.8636 - val_loss: 0.8915 - val_accuracy: 0.8321\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3095 - accuracy: 0.8636 - val_loss: 0.8865 - val_accuracy: 0.8321\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8652 - val_loss: 0.8733 - val_accuracy: 0.8321\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8620 - val_loss: 0.8714 - val_accuracy: 0.8321\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8652 - val_loss: 0.8698 - val_accuracy: 0.8321\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8620 - val_loss: 0.8683 - val_accuracy: 0.8321\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8636 - val_loss: 0.8762 - val_accuracy: 0.8321\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8652 - val_loss: 0.8919 - val_accuracy: 0.8321\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8652 - val_loss: 0.8945 - val_accuracy: 0.8321\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8668 - val_loss: 0.9043 - val_accuracy: 0.8321\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8652 - val_loss: 0.9040 - val_accuracy: 0.8321\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8620 - val_loss: 0.9050 - val_accuracy: 0.8321\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8668 - val_loss: 0.9127 - val_accuracy: 0.8321\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8652 - val_loss: 0.9194 - val_accuracy: 0.8284\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8652 - val_loss: 0.9121 - val_accuracy: 0.8321\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3104 - accuracy: 0.8636 - val_loss: 0.9146 - val_accuracy: 0.8321\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8620 - val_loss: 0.9146 - val_accuracy: 0.8321\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8652 - val_loss: 0.9017 - val_accuracy: 0.8321\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8668 - val_loss: 0.8994 - val_accuracy: 0.8321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8636 - val_loss: 0.8981 - val_accuracy: 0.8321\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8652 - val_loss: 0.9058 - val_accuracy: 0.8321\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8668 - val_loss: 0.9136 - val_accuracy: 0.8321\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8652 - val_loss: 0.8930 - val_accuracy: 0.8321\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8652 - val_loss: 0.8981 - val_accuracy: 0.8321\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3105 - accuracy: 0.8652 - val_loss: 0.8968 - val_accuracy: 0.8321\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8636 - val_loss: 0.9073 - val_accuracy: 0.8321\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3099 - accuracy: 0.8652 - val_loss: 0.8916 - val_accuracy: 0.8284\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8652 - val_loss: 0.8918 - val_accuracy: 0.8284\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8636 - val_loss: 0.9094 - val_accuracy: 0.8246\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.8604 - val_loss: 0.9047 - val_accuracy: 0.8284\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8652 - val_loss: 0.9055 - val_accuracy: 0.8246\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8652 - val_loss: 0.9137 - val_accuracy: 0.8284\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8668 - val_loss: 0.9247 - val_accuracy: 0.8284\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.8668 - val_loss: 0.9283 - val_accuracy: 0.8321\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8636 - val_loss: 0.9221 - val_accuracy: 0.8321\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3095 - accuracy: 0.8668 - val_loss: 0.9299 - val_accuracy: 0.8284\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8652 - val_loss: 0.9244 - val_accuracy: 0.8321\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3105 - accuracy: 0.8652 - val_loss: 0.9127 - val_accuracy: 0.8284\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.8620 - val_loss: 0.9083 - val_accuracy: 0.8321\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8668 - val_loss: 0.9046 - val_accuracy: 0.8321\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8668 - val_loss: 0.9094 - val_accuracy: 0.8321\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8668 - val_loss: 0.9125 - val_accuracy: 0.8284\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8652 - val_loss: 0.9047 - val_accuracy: 0.8321\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8668 - val_loss: 0.9326 - val_accuracy: 0.8246\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3104 - accuracy: 0.8652 - val_loss: 0.9068 - val_accuracy: 0.8284\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.8668 - val_loss: 0.9025 - val_accuracy: 0.8284\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8668 - val_loss: 0.9018 - val_accuracy: 0.8284\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8652 - val_loss: 0.9024 - val_accuracy: 0.8321\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8668 - val_loss: 0.9097 - val_accuracy: 0.8321\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8652 - val_loss: 0.8926 - val_accuracy: 0.8321\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8652 - val_loss: 0.8992 - val_accuracy: 0.8284\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8668 - val_loss: 0.9070 - val_accuracy: 0.8321\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8652 - val_loss: 0.9122 - val_accuracy: 0.8284\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8652 - val_loss: 0.9150 - val_accuracy: 0.8284\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8652 - val_loss: 0.9069 - val_accuracy: 0.8284\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8652 - val_loss: 0.9019 - val_accuracy: 0.8321\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8636 - val_loss: 0.9068 - val_accuracy: 0.8321\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.8652 - val_loss: 0.9150 - val_accuracy: 0.8284\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8668 - val_loss: 0.9154 - val_accuracy: 0.8284\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8636 - val_loss: 0.9169 - val_accuracy: 0.8284\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8620 - val_loss: 0.9248 - val_accuracy: 0.8284\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8652 - val_loss: 0.9286 - val_accuracy: 0.8321\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8668 - val_loss: 0.9345 - val_accuracy: 0.8246\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8652 - val_loss: 0.9323 - val_accuracy: 0.8321\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3101 - accuracy: 0.8652 - val_loss: 0.9333 - val_accuracy: 0.8284\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8668 - val_loss: 0.9298 - val_accuracy: 0.8321\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.8652 - val_loss: 0.9348 - val_accuracy: 0.8321\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.8652 - val_loss: 0.9423 - val_accuracy: 0.8321\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8652 - val_loss: 0.9478 - val_accuracy: 0.8284\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8652 - val_loss: 0.9366 - val_accuracy: 0.8284\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8636 - val_loss: 0.9463 - val_accuracy: 0.8321\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8652 - val_loss: 0.9499 - val_accuracy: 0.8284\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3157 - accuracy: 0.8652 - val_loss: 0.9426 - val_accuracy: 0.8284\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8652 - val_loss: 0.9323 - val_accuracy: 0.8321\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3101 - accuracy: 0.8668 - val_loss: 0.9242 - val_accuracy: 0.8284\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3119 - accuracy: 0.8668 - val_loss: 0.9164 - val_accuracy: 0.8321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8652 - val_loss: 0.9111 - val_accuracy: 0.8321\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8652 - val_loss: 0.8912 - val_accuracy: 0.8284\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.8668 - val_loss: 0.9218 - val_accuracy: 0.8284\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8636 - val_loss: 0.9299 - val_accuracy: 0.8284\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.8604 - val_loss: 0.8558 - val_accuracy: 0.8284\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8668 - val_loss: 0.8567 - val_accuracy: 0.8321\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.8668 - val_loss: 0.8714 - val_accuracy: 0.8321\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8636 - val_loss: 0.8744 - val_accuracy: 0.8321\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8620 - val_loss: 0.8914 - val_accuracy: 0.8321\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8652 - val_loss: 0.8973 - val_accuracy: 0.8321\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8636 - val_loss: 0.9077 - val_accuracy: 0.8284\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8668 - val_loss: 0.9193 - val_accuracy: 0.8284\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8652 - val_loss: 0.9278 - val_accuracy: 0.8321\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8636 - val_loss: 0.9235 - val_accuracy: 0.8321\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8652 - val_loss: 0.9310 - val_accuracy: 0.8321\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8636 - val_loss: 0.9302 - val_accuracy: 0.8284\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8668 - val_loss: 0.9415 - val_accuracy: 0.8321\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8668 - val_loss: 0.9396 - val_accuracy: 0.8321\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8668 - val_loss: 0.9408 - val_accuracy: 0.8321\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8636 - val_loss: 0.9346 - val_accuracy: 0.8284\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8668 - val_loss: 0.9325 - val_accuracy: 0.8321\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8652 - val_loss: 0.9400 - val_accuracy: 0.8321\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8636 - val_loss: 0.9447 - val_accuracy: 0.8284\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8652 - val_loss: 0.9464 - val_accuracy: 0.8321\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8652 - val_loss: 0.9555 - val_accuracy: 0.8321\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8652 - val_loss: 0.9674 - val_accuracy: 0.8321\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8668 - val_loss: 0.9682 - val_accuracy: 0.8321\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8652 - val_loss: 0.9704 - val_accuracy: 0.8321\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.8668 - val_loss: 0.9710 - val_accuracy: 0.8321\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3101 - accuracy: 0.8668 - val_loss: 0.9560 - val_accuracy: 0.8284\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8652 - val_loss: 0.9684 - val_accuracy: 0.8246\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8652 - val_loss: 0.9702 - val_accuracy: 0.8284\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8620 - val_loss: 0.9774 - val_accuracy: 0.8284\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8636 - val_loss: 0.9746 - val_accuracy: 0.8284\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8668 - val_loss: 0.9826 - val_accuracy: 0.8321\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.8652 - val_loss: 0.9743 - val_accuracy: 0.8284\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8668 - val_loss: 0.9743 - val_accuracy: 0.8284\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8636 - val_loss: 0.9798 - val_accuracy: 0.8284\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8668 - val_loss: 0.9730 - val_accuracy: 0.8321\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3118 - accuracy: 0.8668 - val_loss: 0.9580 - val_accuracy: 0.8321\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8652 - val_loss: 0.9496 - val_accuracy: 0.8321\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8668 - val_loss: 0.9593 - val_accuracy: 0.8284\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8668 - val_loss: 0.9551 - val_accuracy: 0.8321\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8636 - val_loss: 0.9646 - val_accuracy: 0.8321\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8668 - val_loss: 0.9719 - val_accuracy: 0.8321\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8652 - val_loss: 0.9705 - val_accuracy: 0.8321\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8668 - val_loss: 0.9891 - val_accuracy: 0.8321\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3100 - accuracy: 0.8668 - val_loss: 0.9954 - val_accuracy: 0.8321\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8668 - val_loss: 0.9954 - val_accuracy: 0.8284\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8652 - val_loss: 1.0024 - val_accuracy: 0.8284\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8652 - val_loss: 1.0122 - val_accuracy: 0.8284\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8636 - val_loss: 1.0152 - val_accuracy: 0.8284\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8652 - val_loss: 1.0085 - val_accuracy: 0.8321\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8636 - val_loss: 1.0096 - val_accuracy: 0.8284\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8636 - val_loss: 1.0301 - val_accuracy: 0.8246\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8652 - val_loss: 1.0306 - val_accuracy: 0.8246\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8652 - val_loss: 1.0322 - val_accuracy: 0.8246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8620 - val_loss: 1.0360 - val_accuracy: 0.8246\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8668 - val_loss: 1.0204 - val_accuracy: 0.8284\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8668 - val_loss: 1.0227 - val_accuracy: 0.8284\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8668 - val_loss: 1.0150 - val_accuracy: 0.8284\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3100 - accuracy: 0.8636 - val_loss: 1.0149 - val_accuracy: 0.8284\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8652 - val_loss: 1.0204 - val_accuracy: 0.8246\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8636 - val_loss: 1.0197 - val_accuracy: 0.8284\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8636 - val_loss: 1.0151 - val_accuracy: 0.8246\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8636 - val_loss: 1.0137 - val_accuracy: 0.8246\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8620 - val_loss: 1.0185 - val_accuracy: 0.8284\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8652 - val_loss: 1.0274 - val_accuracy: 0.8284\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8668 - val_loss: 1.0115 - val_accuracy: 0.8284\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8668 - val_loss: 1.0182 - val_accuracy: 0.8284\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8620 - val_loss: 1.0209 - val_accuracy: 0.8284\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8636 - val_loss: 1.0272 - val_accuracy: 0.8284\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8668 - val_loss: 1.0238 - val_accuracy: 0.8284\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8652 - val_loss: 1.0186 - val_accuracy: 0.8284\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8652 - val_loss: 1.0189 - val_accuracy: 0.8284\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.8668 - val_loss: 0.9725 - val_accuracy: 0.8321\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8636 - val_loss: 0.9409 - val_accuracy: 0.8284\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8652 - val_loss: 0.9524 - val_accuracy: 0.8246\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8636 - val_loss: 0.9831 - val_accuracy: 0.8284\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3141 - accuracy: 0.8636 - val_loss: 0.9852 - val_accuracy: 0.8284\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3116 - accuracy: 0.8652 - val_loss: 0.9536 - val_accuracy: 0.8284\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8652 - val_loss: 0.9445 - val_accuracy: 0.8284\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8620 - val_loss: 0.9901 - val_accuracy: 0.8284\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3099 - accuracy: 0.8652 - val_loss: 0.9711 - val_accuracy: 0.8284\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8668 - val_loss: 0.9660 - val_accuracy: 0.8321\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8620 - val_loss: 0.9594 - val_accuracy: 0.8321\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8636 - val_loss: 0.9787 - val_accuracy: 0.8321\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.8684 - val_loss: 0.9943 - val_accuracy: 0.8246\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.8636 - val_loss: 0.9667 - val_accuracy: 0.8284\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3105 - accuracy: 0.8620 - val_loss: 0.9686 - val_accuracy: 0.8246\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8652 - val_loss: 0.9311 - val_accuracy: 0.8246\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.8668 - val_loss: 0.9547 - val_accuracy: 0.8246\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8668 - val_loss: 0.9539 - val_accuracy: 0.8321\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.8668 - val_loss: 0.9633 - val_accuracy: 0.8321\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8668 - val_loss: 0.9749 - val_accuracy: 0.8321\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8668 - val_loss: 0.9932 - val_accuracy: 0.8321\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8652 - val_loss: 1.0012 - val_accuracy: 0.8321\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3099 - accuracy: 0.8652 - val_loss: 0.9910 - val_accuracy: 0.8284\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8668 - val_loss: 1.0059 - val_accuracy: 0.8284\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.8668 - val_loss: 0.9960 - val_accuracy: 0.8284\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8668 - val_loss: 0.9598 - val_accuracy: 0.8284\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.8652 - val_loss: 0.9744 - val_accuracy: 0.8284\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3126 - accuracy: 0.8636 - val_loss: 0.9718 - val_accuracy: 0.8284\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8636 - val_loss: 0.9648 - val_accuracy: 0.8284\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8668 - val_loss: 0.9650 - val_accuracy: 0.8321\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8668 - val_loss: 0.9781 - val_accuracy: 0.8321\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8668 - val_loss: 0.9944 - val_accuracy: 0.8321\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8668 - val_loss: 1.0014 - val_accuracy: 0.8321\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8668 - val_loss: 1.0092 - val_accuracy: 0.8321\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.8652 - val_loss: 1.0233 - val_accuracy: 0.8321\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8636 - val_loss: 1.0139 - val_accuracy: 0.8321\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8652 - val_loss: 1.0110 - val_accuracy: 0.8321\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8652 - val_loss: 1.0116 - val_accuracy: 0.8321\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8636 - val_loss: 1.0140 - val_accuracy: 0.8321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8652 - val_loss: 1.0206 - val_accuracy: 0.8321\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8652 - val_loss: 1.0299 - val_accuracy: 0.8321\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8668 - val_loss: 1.0414 - val_accuracy: 0.8321\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8652 - val_loss: 1.0477 - val_accuracy: 0.8321\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8668 - val_loss: 1.0517 - val_accuracy: 0.8321\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.8668 - val_loss: 1.0601 - val_accuracy: 0.8321\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8668 - val_loss: 1.0688 - val_accuracy: 0.8284\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8652 - val_loss: 1.0713 - val_accuracy: 0.8321\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8668 - val_loss: 1.0781 - val_accuracy: 0.8321\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8668 - val_loss: 1.0734 - val_accuracy: 0.8321\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8668 - val_loss: 1.1040 - val_accuracy: 0.8321\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8668 - val_loss: 1.0824 - val_accuracy: 0.8321\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8668 - val_loss: 1.0722 - val_accuracy: 0.8321\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.8652 - val_loss: 1.0827 - val_accuracy: 0.8321\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.8668 - val_loss: 1.0889 - val_accuracy: 0.8321\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.8620 - val_loss: 1.0866 - val_accuracy: 0.8321\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8652 - val_loss: 1.0879 - val_accuracy: 0.8321\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3095 - accuracy: 0.8668 - val_loss: 1.0841 - val_accuracy: 0.8321\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8668 - val_loss: 1.0899 - val_accuracy: 0.8321\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8652 - val_loss: 1.0812 - val_accuracy: 0.8321\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8652 - val_loss: 1.0952 - val_accuracy: 0.8321\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8668 - val_loss: 1.0913 - val_accuracy: 0.8321\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8620 - val_loss: 1.0990 - val_accuracy: 0.8284\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8636 - val_loss: 1.0647 - val_accuracy: 0.8284\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8668 - val_loss: 1.0671 - val_accuracy: 0.8284\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8636 - val_loss: 1.0368 - val_accuracy: 0.8284\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8652 - val_loss: 0.9870 - val_accuracy: 0.8284\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8668 - val_loss: 1.0963 - val_accuracy: 0.8284\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8652 - val_loss: 0.8367 - val_accuracy: 0.8284\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3104 - accuracy: 0.8636 - val_loss: 0.9585 - val_accuracy: 0.8246\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8636 - val_loss: 0.9806 - val_accuracy: 0.8209\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8652 - val_loss: 0.9717 - val_accuracy: 0.8209\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8652 - val_loss: 0.9800 - val_accuracy: 0.8209\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8636 - val_loss: 0.9826 - val_accuracy: 0.8246\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8652 - val_loss: 0.9825 - val_accuracy: 0.8246\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8652 - val_loss: 0.9944 - val_accuracy: 0.8246\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8652 - val_loss: 1.0027 - val_accuracy: 0.8284\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8652 - val_loss: 1.0115 - val_accuracy: 0.8284\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8668 - val_loss: 1.0245 - val_accuracy: 0.8284\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8636 - val_loss: 1.0351 - val_accuracy: 0.8284\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8668 - val_loss: 1.0493 - val_accuracy: 0.8284\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8636 - val_loss: 1.0485 - val_accuracy: 0.8284\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.8668 - val_loss: 1.0555 - val_accuracy: 0.8284\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8652 - val_loss: 1.0661 - val_accuracy: 0.8284\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8652 - val_loss: 1.0491 - val_accuracy: 0.8284\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8636 - val_loss: 1.0317 - val_accuracy: 0.8284\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8636 - val_loss: 1.0465 - val_accuracy: 0.8284\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8652 - val_loss: 1.0478 - val_accuracy: 0.8246\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8668 - val_loss: 1.0473 - val_accuracy: 0.8284\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8652 - val_loss: 1.0533 - val_accuracy: 0.8321\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8636 - val_loss: 1.0530 - val_accuracy: 0.8321\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8620 - val_loss: 1.0415 - val_accuracy: 0.8321\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8636 - val_loss: 1.0522 - val_accuracy: 0.8321\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8620 - val_loss: 1.0623 - val_accuracy: 0.8321\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8652 - val_loss: 1.0720 - val_accuracy: 0.8321\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8652 - val_loss: 1.0671 - val_accuracy: 0.8321\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8668 - val_loss: 1.0817 - val_accuracy: 0.8321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8668 - val_loss: 1.0870 - val_accuracy: 0.8321\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8652 - val_loss: 1.0932 - val_accuracy: 0.8321\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8668 - val_loss: 1.0832 - val_accuracy: 0.8321\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8668 - val_loss: 1.0917 - val_accuracy: 0.8321\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8652 - val_loss: 1.1003 - val_accuracy: 0.8321\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8668 - val_loss: 1.0951 - val_accuracy: 0.8321\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.8668 - val_loss: 1.1098 - val_accuracy: 0.8321\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8668 - val_loss: 1.1195 - val_accuracy: 0.8321\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.8652 - val_loss: 1.1147 - val_accuracy: 0.8321\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8668 - val_loss: 1.1043 - val_accuracy: 0.8321\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3104 - accuracy: 0.8684 - val_loss: 1.1190 - val_accuracy: 0.8246\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8668 - val_loss: 1.1264 - val_accuracy: 0.8284\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8652 - val_loss: 1.1086 - val_accuracy: 0.8284\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8668 - val_loss: 1.0953 - val_accuracy: 0.8284\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8652 - val_loss: 1.0921 - val_accuracy: 0.8209\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8668 - val_loss: 1.0865 - val_accuracy: 0.8246\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8668 - val_loss: 1.0970 - val_accuracy: 0.8246\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8652 - val_loss: 1.1017 - val_accuracy: 0.8246\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8652 - val_loss: 1.0954 - val_accuracy: 0.8246\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3099 - accuracy: 0.8636 - val_loss: 1.0974 - val_accuracy: 0.8246\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8668 - val_loss: 1.1028 - val_accuracy: 0.8246\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8668 - val_loss: 1.1107 - val_accuracy: 0.8284\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8652 - val_loss: 1.1054 - val_accuracy: 0.8284\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8636 - val_loss: 1.1119 - val_accuracy: 0.8284\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8668 - val_loss: 1.1234 - val_accuracy: 0.8246\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.8668 - val_loss: 1.1361 - val_accuracy: 0.8284\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8668 - val_loss: 1.1645 - val_accuracy: 0.8284\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8668 - val_loss: 1.1511 - val_accuracy: 0.8284\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8668 - val_loss: 1.1423 - val_accuracy: 0.8246\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8652 - val_loss: 1.1674 - val_accuracy: 0.8246\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8668 - val_loss: 1.1643 - val_accuracy: 0.8284\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8668 - val_loss: 1.1874 - val_accuracy: 0.8321\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3095 - accuracy: 0.8668 - val_loss: 1.2217 - val_accuracy: 0.8284\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8652 - val_loss: 1.0285 - val_accuracy: 0.8321\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8652 - val_loss: 1.0549 - val_accuracy: 0.8321\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8652 - val_loss: 1.0784 - val_accuracy: 0.8321\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8652 - val_loss: 1.0835 - val_accuracy: 0.8321\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8668 - val_loss: 1.0882 - val_accuracy: 0.8284\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8668 - val_loss: 1.1306 - val_accuracy: 0.8284\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8652 - val_loss: 1.1709 - val_accuracy: 0.8284\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3224 - accuracy: 0.8636 - val_loss: 0.9263 - val_accuracy: 0.8321\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8668 - val_loss: 1.0172 - val_accuracy: 0.8284\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3101 - accuracy: 0.8652 - val_loss: 1.0121 - val_accuracy: 0.8321\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8652 - val_loss: 1.0214 - val_accuracy: 0.8321\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8652 - val_loss: 1.0187 - val_accuracy: 0.8321\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8652 - val_loss: 1.0253 - val_accuracy: 0.8321\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8620 - val_loss: 1.0394 - val_accuracy: 0.8321\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8652 - val_loss: 1.0583 - val_accuracy: 0.8284\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8636 - val_loss: 1.0388 - val_accuracy: 0.8321\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8652 - val_loss: 1.0573 - val_accuracy: 0.8284\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8668 - val_loss: 1.0714 - val_accuracy: 0.8321\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8668 - val_loss: 1.0809 - val_accuracy: 0.8321\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8652 - val_loss: 1.0768 - val_accuracy: 0.8284\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8684 - val_loss: 1.0914 - val_accuracy: 0.8246\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.8652 - val_loss: 1.0645 - val_accuracy: 0.8284\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8636 - val_loss: 1.0492 - val_accuracy: 0.8284\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8668 - val_loss: 1.0574 - val_accuracy: 0.8284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8636 - val_loss: 1.0708 - val_accuracy: 0.8284\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8668 - val_loss: 1.0690 - val_accuracy: 0.8284\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8652 - val_loss: 1.0762 - val_accuracy: 0.8321\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8652 - val_loss: 1.0750 - val_accuracy: 0.8246\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8636 - val_loss: 1.0788 - val_accuracy: 0.8284\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8652 - val_loss: 1.0928 - val_accuracy: 0.8246\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.8668 - val_loss: 1.1084 - val_accuracy: 0.8246\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.8652 - val_loss: 1.1211 - val_accuracy: 0.8246\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8668 - val_loss: 1.0698 - val_accuracy: 0.8246\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.8636 - val_loss: 0.9969 - val_accuracy: 0.8284\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8652 - val_loss: 1.0153 - val_accuracy: 0.8284\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8668 - val_loss: 1.0269 - val_accuracy: 0.8284\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8668 - val_loss: 1.0494 - val_accuracy: 0.8246\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.8668 - val_loss: 1.0632 - val_accuracy: 0.8209\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8652 - val_loss: 1.0728 - val_accuracy: 0.8246\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8652 - val_loss: 1.0770 - val_accuracy: 0.8246\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8652 - val_loss: 1.0778 - val_accuracy: 0.8246\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8668 - val_loss: 1.0913 - val_accuracy: 0.8246\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8636 - val_loss: 1.0918 - val_accuracy: 0.8284\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8668 - val_loss: 1.0877 - val_accuracy: 0.8284\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8636 - val_loss: 1.1005 - val_accuracy: 0.8321\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8652 - val_loss: 1.0971 - val_accuracy: 0.8321\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8652 - val_loss: 1.1089 - val_accuracy: 0.8284\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8652 - val_loss: 1.1141 - val_accuracy: 0.8284\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8652 - val_loss: 1.1117 - val_accuracy: 0.8284\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8620 - val_loss: 1.1264 - val_accuracy: 0.8284\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8636 - val_loss: 1.1275 - val_accuracy: 0.8284\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8636 - val_loss: 1.1312 - val_accuracy: 0.8321\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8668 - val_loss: 1.1295 - val_accuracy: 0.8321\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8620 - val_loss: 1.1316 - val_accuracy: 0.8321\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8636 - val_loss: 1.1130 - val_accuracy: 0.8246\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8668 - val_loss: 1.1023 - val_accuracy: 0.8284\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8668 - val_loss: 1.1069 - val_accuracy: 0.8284\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8652 - val_loss: 1.1246 - val_accuracy: 0.8284\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8668 - val_loss: 1.1075 - val_accuracy: 0.8284\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8652 - val_loss: 1.1023 - val_accuracy: 0.8284\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8668 - val_loss: 1.0988 - val_accuracy: 0.8284\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8652 - val_loss: 1.0944 - val_accuracy: 0.8284\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.8652 - val_loss: 1.1063 - val_accuracy: 0.8284\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8668 - val_loss: 1.1114 - val_accuracy: 0.8284\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8668 - val_loss: 1.1126 - val_accuracy: 0.8284\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8668 - val_loss: 1.1158 - val_accuracy: 0.8246\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8652 - val_loss: 1.1120 - val_accuracy: 0.8321\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8636 - val_loss: 1.1226 - val_accuracy: 0.8284\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8636 - val_loss: 1.1189 - val_accuracy: 0.8284\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8668 - val_loss: 1.1422 - val_accuracy: 0.8246\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8668 - val_loss: 1.1348 - val_accuracy: 0.8284\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8668 - val_loss: 1.1386 - val_accuracy: 0.8284\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8668 - val_loss: 1.1374 - val_accuracy: 0.8321\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8652 - val_loss: 1.1546 - val_accuracy: 0.8321\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.8668 - val_loss: 1.1341 - val_accuracy: 0.8321\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8620 - val_loss: 1.1376 - val_accuracy: 0.8284\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8652 - val_loss: 1.1533 - val_accuracy: 0.8284\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3130 - accuracy: 0.8620 - val_loss: 1.1360 - val_accuracy: 0.8284\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3095 - accuracy: 0.8684 - val_loss: 1.0980 - val_accuracy: 0.8284\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8668 - val_loss: 1.0978 - val_accuracy: 0.8284\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8636 - val_loss: 1.0947 - val_accuracy: 0.8284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.8652 - val_loss: 1.1090 - val_accuracy: 0.8246\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8668 - val_loss: 1.1161 - val_accuracy: 0.8246\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8620 - val_loss: 1.1206 - val_accuracy: 0.8246\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8668 - val_loss: 1.1460 - val_accuracy: 0.8284\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3150 - accuracy: 0.8668 - val_loss: 1.1170 - val_accuracy: 0.8284\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8668 - val_loss: 1.0945 - val_accuracy: 0.8284\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8636 - val_loss: 1.0972 - val_accuracy: 0.8284\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8668 - val_loss: 1.1366 - val_accuracy: 0.8321\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3163 - accuracy: 0.8620 - val_loss: 1.0177 - val_accuracy: 0.8284\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8668 - val_loss: 0.9486 - val_accuracy: 0.8284\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3186 - accuracy: 0.8652 - val_loss: 1.0416 - val_accuracy: 0.8284\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.8668 - val_loss: 1.1590 - val_accuracy: 0.8284\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.8652 - val_loss: 1.1653 - val_accuracy: 0.8284\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8636 - val_loss: 1.1658 - val_accuracy: 0.8284\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3329 - accuracy: 0.8652 - val_loss: 1.1654 - val_accuracy: 0.8284\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8604 - val_loss: 1.2558 - val_accuracy: 0.8209\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8620 - val_loss: 1.1723 - val_accuracy: 0.8284\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3368 - accuracy: 0.8652 - val_loss: 1.1271 - val_accuracy: 0.8284\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.8668 - val_loss: 1.1743 - val_accuracy: 0.8246\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3122 - accuracy: 0.8652 - val_loss: 1.2436 - val_accuracy: 0.8284\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.8652 - val_loss: 1.2652 - val_accuracy: 0.8246\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8668 - val_loss: 1.2886 - val_accuracy: 0.8246\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8668 - val_loss: 1.2818 - val_accuracy: 0.8246\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8668 - val_loss: 1.3112 - val_accuracy: 0.8246\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8668 - val_loss: 1.3127 - val_accuracy: 0.8246\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8668 - val_loss: 1.3118 - val_accuracy: 0.8246\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8668 - val_loss: 1.3140 - val_accuracy: 0.8246\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8636 - val_loss: 1.3139 - val_accuracy: 0.8246\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8668 - val_loss: 1.3220 - val_accuracy: 0.8246\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8652 - val_loss: 1.3192 - val_accuracy: 0.8246\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8652 - val_loss: 1.3147 - val_accuracy: 0.8246\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8668 - val_loss: 1.3277 - val_accuracy: 0.8246\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.8668 - val_loss: 1.3256 - val_accuracy: 0.8246\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8668 - val_loss: 1.3132 - val_accuracy: 0.8246\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8652 - val_loss: 1.3100 - val_accuracy: 0.8246\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8636 - val_loss: 1.3140 - val_accuracy: 0.8246\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8636 - val_loss: 1.3170 - val_accuracy: 0.8246\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8652 - val_loss: 1.3169 - val_accuracy: 0.8246\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8652 - val_loss: 1.3385 - val_accuracy: 0.8246\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8652 - val_loss: 1.3310 - val_accuracy: 0.8246\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8668 - val_loss: 1.3272 - val_accuracy: 0.8246\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8652 - val_loss: 1.3212 - val_accuracy: 0.8246\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3095 - accuracy: 0.8668 - val_loss: 1.3268 - val_accuracy: 0.8209\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8652 - val_loss: 1.3365 - val_accuracy: 0.8246\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8652 - val_loss: 1.3483 - val_accuracy: 0.8209\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8668 - val_loss: 1.3462 - val_accuracy: 0.8246\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8652 - val_loss: 1.3529 - val_accuracy: 0.8246\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8652 - val_loss: 1.3504 - val_accuracy: 0.8246\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8636 - val_loss: 1.3640 - val_accuracy: 0.8246\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8652 - val_loss: 1.3650 - val_accuracy: 0.8246\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8652 - val_loss: 1.3686 - val_accuracy: 0.8246\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.8636 - val_loss: 1.3680 - val_accuracy: 0.8246\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8652 - val_loss: 1.3702 - val_accuracy: 0.8246\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.8668 - val_loss: 1.3677 - val_accuracy: 0.8246\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3095 - accuracy: 0.8652 - val_loss: 1.3837 - val_accuracy: 0.8246\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8652 - val_loss: 1.4129 - val_accuracy: 0.8246\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3829 - accuracy: 0.8604 - val_loss: 1.2950 - val_accuracy: 0.8284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.8636 - val_loss: 1.3586 - val_accuracy: 0.8246\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3122 - accuracy: 0.8668 - val_loss: 1.2617 - val_accuracy: 0.8284\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.8652 - val_loss: 1.2867 - val_accuracy: 0.8284\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8668 - val_loss: 1.2898 - val_accuracy: 0.8284\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.8668 - val_loss: 1.3050 - val_accuracy: 0.8284\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3100 - accuracy: 0.8668 - val_loss: 1.3115 - val_accuracy: 0.8284\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8668 - val_loss: 1.3154 - val_accuracy: 0.8284\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8652 - val_loss: 1.3202 - val_accuracy: 0.8284\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8652 - val_loss: 1.3257 - val_accuracy: 0.8284\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8668 - val_loss: 1.3334 - val_accuracy: 0.8284\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.8620 - val_loss: 1.3442 - val_accuracy: 0.8284\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8668 - val_loss: 1.3433 - val_accuracy: 0.8284\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8652 - val_loss: 1.3473 - val_accuracy: 0.8284\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8652 - val_loss: 1.3610 - val_accuracy: 0.8284\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.8652 - val_loss: 1.3638 - val_accuracy: 0.8284\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8652 - val_loss: 1.3625 - val_accuracy: 0.8284\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8668 - val_loss: 1.3642 - val_accuracy: 0.8321\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8636 - val_loss: 1.3892 - val_accuracy: 0.8284\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8668 - val_loss: 1.4094 - val_accuracy: 0.8284\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8636 - val_loss: 1.3875 - val_accuracy: 0.8246\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8652 - val_loss: 1.3617 - val_accuracy: 0.8246\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8652 - val_loss: 1.3656 - val_accuracy: 0.8284\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8668 - val_loss: 1.3653 - val_accuracy: 0.8284\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8636 - val_loss: 1.3698 - val_accuracy: 0.8284\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8636 - val_loss: 1.3809 - val_accuracy: 0.8284\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8652 - val_loss: 1.3751 - val_accuracy: 0.8284\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8652 - val_loss: 1.3685 - val_accuracy: 0.8284\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8652 - val_loss: 1.3658 - val_accuracy: 0.8284\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8668 - val_loss: 1.3758 - val_accuracy: 0.8284\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8636 - val_loss: 1.3719 - val_accuracy: 0.8284\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8668 - val_loss: 1.3766 - val_accuracy: 0.8284\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8668 - val_loss: 1.3912 - val_accuracy: 0.8284\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8652 - val_loss: 1.3755 - val_accuracy: 0.8284\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8652 - val_loss: 1.3829 - val_accuracy: 0.8284\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8604 - val_loss: 1.3734 - val_accuracy: 0.8284\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8620 - val_loss: 1.3772 - val_accuracy: 0.8284\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3058 - accuracy: 0.8636 - val_loss: 1.3805 - val_accuracy: 0.8284\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8636 - val_loss: 1.3894 - val_accuracy: 0.8284\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.8636 - val_loss: 1.3832 - val_accuracy: 0.8284\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8636 - val_loss: 1.3853 - val_accuracy: 0.8284\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8668 - val_loss: 1.3778 - val_accuracy: 0.8284\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8668 - val_loss: 1.3986 - val_accuracy: 0.8284\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.8668 - val_loss: 1.3933 - val_accuracy: 0.8284\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8652 - val_loss: 1.3938 - val_accuracy: 0.8284\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.8668 - val_loss: 1.4005 - val_accuracy: 0.8284\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8636 - val_loss: 1.3963 - val_accuracy: 0.8284\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8652 - val_loss: 1.3995 - val_accuracy: 0.8284\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3069 - accuracy: 0.8668 - val_loss: 1.4043 - val_accuracy: 0.8284\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8620 - val_loss: 1.4074 - val_accuracy: 0.8284\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8652 - val_loss: 1.4095 - val_accuracy: 0.8284\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8652 - val_loss: 1.4148 - val_accuracy: 0.8284\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8652 - val_loss: 1.4142 - val_accuracy: 0.8284\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8652 - val_loss: 1.4248 - val_accuracy: 0.8284\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8636 - val_loss: 1.4230 - val_accuracy: 0.8246\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8636 - val_loss: 1.4271 - val_accuracy: 0.8284\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8652 - val_loss: 1.4263 - val_accuracy: 0.8284\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8668 - val_loss: 1.4321 - val_accuracy: 0.8284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3069 - accuracy: 0.8620 - val_loss: 1.4220 - val_accuracy: 0.8284\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8652 - val_loss: 1.4397 - val_accuracy: 0.8284\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8668 - val_loss: 1.4279 - val_accuracy: 0.8284\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8652 - val_loss: 1.4318 - val_accuracy: 0.8284\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8652 - val_loss: 1.4330 - val_accuracy: 0.8284\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8668 - val_loss: 1.4355 - val_accuracy: 0.8284\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8668 - val_loss: 1.4336 - val_accuracy: 0.8284\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.8668 - val_loss: 1.4474 - val_accuracy: 0.8284\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3063 - accuracy: 0.8668 - val_loss: 1.4467 - val_accuracy: 0.8284\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3069 - accuracy: 0.8652 - val_loss: 1.4434 - val_accuracy: 0.8284\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8652 - val_loss: 1.4500 - val_accuracy: 0.8284\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8620 - val_loss: 1.4542 - val_accuracy: 0.8284\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8652 - val_loss: 1.4548 - val_accuracy: 0.8284\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8668 - val_loss: 1.4495 - val_accuracy: 0.8284\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8652 - val_loss: 1.4509 - val_accuracy: 0.8284\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8668 - val_loss: 1.4570 - val_accuracy: 0.8284\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8652 - val_loss: 1.4565 - val_accuracy: 0.8284\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8668 - val_loss: 1.4364 - val_accuracy: 0.8246\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8620 - val_loss: 1.4480 - val_accuracy: 0.8284\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8652 - val_loss: 1.4633 - val_accuracy: 0.8284\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8652 - val_loss: 1.4665 - val_accuracy: 0.8284\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8636 - val_loss: 1.4621 - val_accuracy: 0.8284\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8652 - val_loss: 1.4727 - val_accuracy: 0.8284\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.8652 - val_loss: 1.4623 - val_accuracy: 0.8284\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8636 - val_loss: 1.4663 - val_accuracy: 0.8284\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8652 - val_loss: 1.4716 - val_accuracy: 0.8284\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3069 - accuracy: 0.8668 - val_loss: 1.4708 - val_accuracy: 0.8284\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8668 - val_loss: 1.4577 - val_accuracy: 0.8284\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8668 - val_loss: 1.4527 - val_accuracy: 0.8284\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8668 - val_loss: 1.4578 - val_accuracy: 0.8284\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8652 - val_loss: 1.4729 - val_accuracy: 0.8284\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "3b738d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8552188552188552\n"
     ]
    }
   ],
   "source": [
    "def get_answer(pred):\n",
    "    return np.where(pred>0.5, 1, 0).squeeze()\n",
    "\n",
    "pred_train = model.predict(X_test)\n",
    "answer_train = get_answer(pred_train)\n",
    "\n",
    "def compare_test(answer, y):\n",
    "    compare = (answer==y)\n",
    "    print(compare.value_counts()[True] / len(compare))\n",
    "compare_test(answer_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "fd757b86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "4c97f125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission_output(answer):\n",
    "    submission_df['Survived'] = answer\n",
    "    submission_df.to_csv('submission.csv', index=False)\n",
    "    !kaggle competitions submit -c titanic -f submission.csv -m \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "f5ce9a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(test_X)\n",
    "answer_test = get_answer(test_pred)\n",
    "submission_output(answer_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb5bcd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "b819ff1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "4f83e74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7985074626865671\n"
     ]
    }
   ],
   "source": [
    "answer_train=lr.predict(X_test)\n",
    "compare_test(answer_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "adbc54f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to Titanic - Machine Learning from Disaster\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/3.18k [00:00<?, ?B/s]\n",
      "100%|##########| 3.18k/3.18k [00:00<00:00, 22.6kB/s]\n",
      "100%|##########| 3.18k/3.18k [00:03<00:00, 931B/s]  \n"
     ]
    }
   ],
   "source": [
    "answer_test = lr.predict(test_X)\n",
    "submission_output(answer_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e209d669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "2d043302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "cef77d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7761194029850746\n"
     ]
    }
   ],
   "source": [
    "answer_train=dtc.predict(X_test)\n",
    "compare_test(answer_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "7bb71ff6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to Titanic - Machine Learning from Disaster\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/3.18k [00:00<?, ?B/s]\n",
      "100%|##########| 3.18k/3.18k [00:00<00:00, 20.2kB/s]\n",
      "100%|##########| 3.18k/3.18k [00:02<00:00, 1.34kB/s]\n"
     ]
    }
   ],
   "source": [
    "answer_test = dtc.predict(test_X)\n",
    "submission_output(answer_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f498f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "cdd71a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=5)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd_clf = RandomForestClassifier(n_estimators=100, max_depth=5)\n",
    "rd_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "955d07ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7947761194029851\n"
     ]
    }
   ],
   "source": [
    "answer_train=rd_clf.predict(X_test)\n",
    "compare_test(answer_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "90cd1a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to Titanic - Machine Learning from Disaster\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/3.18k [00:00<?, ?B/s]\n",
      "100%|##########| 3.18k/3.18k [00:00<00:00, 22.7kB/s]\n",
      "100%|##########| 3.18k/3.18k [00:03<00:00, 936B/s]  \n"
     ]
    }
   ],
   "source": [
    "answer_test = rd_clf.predict(test_X)\n",
    "submission_output(answer_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7681ddf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "cddd205d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "4c45b28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7835820895522388\n"
     ]
    }
   ],
   "source": [
    "answer_train=gb.predict(X_test)\n",
    "compare_test(answer_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "af6b92cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 - Bad Request\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/3.18k [00:00<?, ?B/s]\n",
      "100%|##########| 3.18k/3.18k [00:00<00:00, 21.3kB/s]\n",
      "100%|##########| 3.18k/3.18k [00:02<00:00, 1.11kB/s]\n"
     ]
    }
   ],
   "source": [
    "answer_test = gb.predict(test_X)\n",
    "submission_output(answer_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4c5dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "511431ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.1, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=5, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=180,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.1, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=5, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=180,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.1, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=5, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=180,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(booster = 'gbtree', learning_rate = 0.1, max_depth = 5, n_estimators = 180)\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "989ae01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7947761194029851\n"
     ]
    }
   ],
   "source": [
    "answer_train=xgb.predict(X_test)\n",
    "compare_test(answer_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "5eff3955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 - Bad Request\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/3.18k [00:00<?, ?B/s]\n",
      "100%|##########| 3.18k/3.18k [00:00<00:00, 22.4kB/s]\n",
      "100%|##########| 3.18k/3.18k [00:02<00:00, 1.09kB/s]\n"
     ]
    }
   ],
   "source": [
    "answer_test = xgb.predict(test_X)\n",
    "submission_output(answer_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ece4d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5de627",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
